参考：

- [吴恩达机器学习](http://study.163.com/course/introduction/1004570029.htm)
- [梯度下降法及其Python实现](https://blog.csdn.net/yhao2014/article/details/51554910)
- [梯度下降法(BGD,SGD,MSGD)python+numpy具体实现](https://blog.csdn.net/pengjian444/article/details/71075544)
- [Octave](http://www.gnu.org/software/octave/)
- [Octave 的函數列表](http://ccckmit.wikidot.com/oc:lib)
- [在线公式编辑器](http://latex.codecogs.com/eqneditor/editor.php)

----------
# 1、绪论：初识机器学习
![这里写图片描述](http://img.blog.csdn.net/20180408111604623?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 什么是机器学习
![这里写图片描述](http://img.blog.csdn.net/20180408112126794?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408112137643?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408112536787?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 监督学习
![这里写图片描述](http://img.blog.csdn.net/20180408120157872?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408120206077?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408120215143?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 课时4 无监督学习

数据聚类

![这里写图片描述](http://img.blog.csdn.net/20180408121712505?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408121722698?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408121732400?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408121740754?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


----------


# 第2章 单变量线性回归

## 模型描述
![这里写图片描述](http://img.blog.csdn.net/20180408154551331?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408154600748?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 代价函数
![这里写图片描述](http://img.blog.csdn.net/20180408155554926?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408155603248?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 代价函数（一）
![这里写图片描述](http://img.blog.csdn.net/20180408161605032?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408161615195?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408161624041?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 代价函数（二）
![这里写图片描述](http://img.blog.csdn.net/20180408163542542?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408163550444?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408163557190?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 梯度下降
![这里写图片描述](http://img.blog.csdn.net/20180408164925852?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408164933558?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408164940395?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 梯度下降知识点总结
![这里写图片描述](http://img.blog.csdn.net/20180408170454290?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408170505596?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408170513347?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408170521448?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408170529186?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408170537438?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408170544316?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 线性回归的梯度下降
![这里写图片描述](http://img.blog.csdn.net/20180408172332972?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408172341073?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408172348704?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


----------

# 线性回归梯度下降公式总结

![这里写图片描述](http://img.blog.csdn.net/20180408184741889?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


**Hypothesis:** $h_{\theta }=\theta_{0}+\theta_{1}x$

**Parameters:** $\theta_{0},\theta_{1}$

**Cost Function:** $J(\theta_{0},\theta_{1})=\frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^{2}$

**Goal:** $minimizeJ(\theta_{0},\theta_{1})$


----------


**Gradient descent algorithm:**
$\theta_{j}:=\theta_{j}-\alpha \frac{\partial }{\partial \theta_{j}}J(\theta_{0},\theta_{1})  (for j=0 and j=1)$

**Correct:Simultaneous update**

$temp0:\theta_{0}-\alpha \frac{\partial }{\partial \theta_{0}}J(\theta_{0},\theta_{1})$

$temp1:\theta_{1}-\alpha \frac{\partial }{\partial \theta_{1}}J(\theta_{0},\theta_{1})$

$\theta_{0}=temp0$
$\theta_{1}=temp1$


----------


# 第3章 线性回归回顾
## 矩阵和向量

![这里写图片描述](http://img.blog.csdn.net/20180408182810822?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


----------


# 第4章 配置

## 安装 MATLAB
参考：https://www.mathworks.com/licensecenter/classroom/machine_learning_od/

## 在 Windows 上安装 Octave
参考：http://www.gnu.org/software/octave/

## GNU/Linux 上安装 Octave
参考：http://www.gnu.org/software/octave/

## 更多 Octave/MATLAB  资源


----------
# 第5章 多变量线性回归
## 多功能

![这里写图片描述](http://img.blog.csdn.net/20180408211351040?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408211400254?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 多元梯度下降法

![这里写图片描述](http://img.blog.csdn.net/20180408211900929?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![ ](http://img.blog.csdn.net/20180408211908415?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 多元梯度下降法演练 I – 特征缩放
![这里写图片描述](http://img.blog.csdn.net/20180408213619593?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408213627671?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408213635265?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

```python
import numpy as np

x=[[100,200,255],[120,30,70],[70,90,100],[200,110,40]]
x=np.asarray(x)

x_=(x-np.mean(x,0))/np.std(x,0)
x__=(x-np.min(x,0))/(np.max(x,0)-np.min(x,0))
x___=(x-np.mean(x,0))/np.max(x)
x____=x/np.max(x)-0.5
```

## 多元梯度下降法II – 学习率
![这里写图片描述](http://img.blog.csdn.net/20180408215239005?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408215246251?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408215253454?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 特征和多项式回归
![这里写图片描述](http://img.blog.csdn.net/20180408220703256?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408220711263?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 正规方程（区别于迭代方法的直接解法）
样本特征数 少于1W的 **回归问题**时，使用 $\theta=(X^{T}X)^{-1}X^{T}y$ ,这种常规方法求参数，（替代梯度下降方法，但在分类问题时，只能使用梯度下降方法）
![这里写图片描述](http://img.blog.csdn.net/20180408223224229?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408223236435?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408223244177?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408223251639?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408223258605?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 正规方程在矩阵不可逆情况下的解决方法
![这里写图片描述](http://img.blog.csdn.net/20180408224029383?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408224037497?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


----------
# 第6章 Octave/Matlab 教程
## 基本操作

```python
>>>a=pi
a =  3.1416
>>>a
a =  3.1416
>>>disp(a)
 3.1416
>>>disp(sprintf('2 decimals:%0.2f',a))
2 decimals:3.14
>>>disp(sprintf('6 decimals:%0.6f',a))
6 decimals:3.141593
>>>a
a =  3.1416
>>>format long
>>>a
a =  3.14159265358979
>>>format short
>>>a
a =  3.1416

>>>A=[1 2;3,4;5,6]
A =

   1   2
   3   4
   5   6

>>>A=[1 2;
> 3,4;
> 5 6]
A =

   1   2
   3   4
   5   6

>>>v=[1 2 3]
v =

   1   2   3

>>>v=[1 ;2 ;3]
v =

   1
   2
   3


>>>ones(2,3)
ans =

   1   1   1
   1   1   1

>>>C=2*ones(2,3)
C =

   2   2   2
   2   2   2

>>>C=[2,2,2;2,2,2]
C =

   2   2   2
   2   2   2


>>>w=zeros(1,3)
w =

   0   0   0

>>>w=ones(1,3)
w =

   1   1   1

>>>w=rand(1,3)  # 0~1 之间的随机数
w =

   0.70559   0.59973   0.82269

>>>w=randn(1,3) # 均值为0,方差为1 的随机数
w =

  -0.28337   0.29570   0.41274

>>>w=-6*sqrt(10)*(randn(1,10000));
>>>hist(w) # 画直方图
>>>hist(w,60) # 直方图的条数为60

>>>v=1:10 # 1~10 默认步长为1 类似numpy range(1,10)
v =

    1    2    3    4    5    6    7    8    9   10

>>>v=1:2:10 # 1~10 步长为2 类似numpy range(1,10,2)
v =

   1   3   5   7   9

```

> help eye  % 帮助函数
> eye   % 单位矩阵
> PS1('>>>');  % 改变显示

## 移动数据
> who   显示当前工作空间所有变量
> whos  显示更详细的信息
> clear 变量名  % 删除该变量
> clc %清除屏幕 不会清除变量

```python
>>>A=[1 2;3 4;5 6]
A =

   1   2
   3   4
   5   6

>>>size(A)
ans =

   3   2

>>>size(A,1)
ans =  3
>>>size(A,2)
ans =  2
>>>size(A,3)
ans =  1
>>>length (A)
ans =  3
>>>B=[1 2 3;2 3 4]
B =

   1   2   3
   2   3   4

>>>length (B)
ans =  3
>>>size(B)
ans =

   2   3


>>>pwd # 显示当前环境路径
ans = E:\
>>>cd 'E:\' # 切换路径
>>>pwd
ans = E:\
>>>ls # 显示目录
 E:\ 的目录
```

```python
>>> vim data.dat
'''
1 2 3
32 12 24
123 11 22
1 123 125
'''


>>>load data.dat # 加载数据
>>>load('data.dat') # 或者这样加载数据
>>>who # 显示当前工作空间中所有变量
Variables in the current scope:

data

>>>whos # 显示当前工作空间中所有变量（更详细）
Variables in the current scope:

   Attr Name        Size                     Bytes  Class
   ==== ====        ====                     =====  =====
        data        4x3                         96  double

Total is 12 elements using 96 bytes

>>>data
data =

     1     2     3
    32    12    24
   123    11    22
     1   123   125

>>>v=data(1:2,2:3)
v =

    2    3
   12   24
>>>save hello.mat v; # 将变量v保存成 hello.mat

>>>clear # 清除所有变量
>>>whos
>>>who
>>>load hello.mat # 加载文件
>>>whos # 查看内存变量
Variables in the current scope:

   Attr Name        Size                     Bytes  Class
   ==== ====        ====                     =====  =====
        v           2x2                         32  double

Total is 4 elements using 32 bytes

>>>v
v =

    2    3
   12   24


>>>save hello.txt v

vim hello.txt # 保存成txt文件
'''
# Created by Octave 4.2.2, Tue Apr 10 22:41:17 2018 GMT <unknown@unknown>
# name: v
# type: matrix
# rows: 2
# columns: 2
 2 3
 12 24
'''
# --------------------------------------------

>>>save hello.txt v -ascii % save as text(ASCII)
vim hello.txt
'''
 2.00000000e+000 3.00000000e+000
 1.20000000e+001 2.40000000e+001
'''
```

```python
>>>A=[1 2;3 4;5 6]
A =

   1   2
   3   4
   5   6

>>>A(3,2) # 第3行第2列的元素
ans =  6
>>>A(2,:) # 第2行
ans =

   3   4

>>>A(:,2) # 第2列
ans =

   2
   4
   6

>>>A([1,3],:) # 第1行与第3行
ans =

   1   2
   5   6

>>>A(:,2)=[10;11;12] # 修改第2列
A =

    1   10
    3   11
    5   12

>>>A=[A,[100;101;102]] # 增加一列
A =

     1    10   100
     3    11   101
     5    12   102

>>>A=[A;[10 20 30]] # 增加一行
A =

     1    10   100
     3    11   101
     5    12   102
    10    20    30

>>>A(:)  # 获取A中的所有元素
ans =
     1
     3
     5
    10
    10
    11
    12
    20
   100
   101
   102
    30

>>>size(ans)
ans =

   12    1

>>>A=[1 2;3 4;5 6]
A =

   1   2
   3   4
   5   6

>>>B=[10 11;12 13;14 15]
B =

   10   11
   12   13
   14   15

>>>C=[A B] # 按列合并
C =

    1    2   10   11
    3    4   12   13
    5    6   14   15

>>>D=[A;B] # 按行合并
D =

    1    2
    3    4
    5    6
   10   11
   12   13
   14   15

```
## 计算数据

> A*B  %矩阵乘法
> A.*B  %矩阵对应元素相乘
> A.^2  % 等价于 A.*A
> 1./A  % 矩阵A中对应元素取倒数
> log(A)  % 矩阵A中的元素取对数（自然对数 e为底）
> exp(A)  % 矩阵A中的元素指数（自然对数 e为底）
> abs(A)  % 绝对值
> A+1   % 矩阵A中的元素都加1  等价于 A+ones(size(A))
> A'  % A 转置
> max(A)  按列求最大值，等价于max(A,[],1)  ;  max(A,[],2)按行求和
> A<3  # 小于3返回1(True)否则返回0（False）
> find(A<3) # 找到A中小于3 的元素索引（A按列展开的）
> [r,c]=find(A>7)  # 返回索引r 行，c 列
> A=magic (3) # 魔幻矩阵 每一行，每一列，对角线上的元素之和都相同
> help find  # 查看函数帮助
> sum(A) # 按列求和 等价于sum(A,1)  ;  sum(A,2)按行求和
> sum(sum(A.*eye(size(A)))) # 求主对角线上的元素之和
> sum(sum(A.*flipud(eye(size(A))))) # 求次对角线上的元素之和
> flipud（A） # 上下翻转矩阵
> prod(A)  # 按列求积 等价于prod(A,1)  ;  prod(A,2)按行求和
> floor(A)  # 向下取整 0.5-->0 ;0.2-->0;0.7-->0
> ceil(A)  # 向上取整 0.5-->1 ;0.2-->1;0.7-->1
> round（A） # 四舍五入  0.5-->1 ;0.2-->0;0.7-->1
> max(rand(3),rand(3)) # 返回2个随机矩阵中对应位置最大值组成新的矩阵
> pinv(A) # 矩阵求逆（伪逆） A即使不可逆，也能求
> inv（A） # 矩阵求逆， A即使不可逆，不能求

```python
A =

   1   2
   3   4
   5   6

>>>[val,ind]=max(A) # val返回的最大值，ind为返回的最大值位置
val =

   5   6

ind =

   3   3

>>>[val,ind]=max(A,[],1) # 按列求最大值
val =

   5   6

ind =

   3   3

>>>[val,ind]=max(A,[],2) # 按行求最大值
val =

   2
   4
   6

ind =

   2
   2
   2

>>>A<3 # 小于3返回1(True)否则返回0（False）
ans =

  1  1
  0  0
  0  0


>>>find(A<3) # 找到A中小于3 的元素索引（A按列展开的）
ans =

   1
   4

>>>find(A(:)<3) # A(:) 矩阵A按列展开
ans =

   1
   4

>>>A=magic (3) # 魔幻矩阵 每一行，每一列，对角线上的元素之和都相同
A =

   8   1   6 # 15
   3   5   7 # 15
   4   9   2 # 15


>>>find(A>7)
ans =

   1
   6

>>>[r,c]=find(A>7)
r =

   1
   3

c =

   1
   2
   
>>>A(1,1)
ans =  8
>>>A(3,2)
ans =  9
```

## 数据绘制

```python
>> t=[0:0.01:0.98];
>> y1=sin(2*pi*4*t);
>> plot(t,y1);
>> y2=cos(2*pi*4*t);
>> plot(t,y2); # 默认会覆盖掉前一次的绘画
>> hold on; # 保持前面的绘画
>> plot(t,y1,'r'); # 在前一次的绘画上继续绘画
>> xlabel('time')
>> ylabel ('value')
>> legend('cos','sin') # 图例，顺序对应
>> title('my plot')
>> print -dpng 'myplot.png' # 保存绘画
>> close # 关闭绘画

>> figure(1);plot(t,y1); # 第一张图上绘画
>> figure(2);plot(t,y2); # 第二张图上绘画（不会覆盖前一张图）

>> subplot(121);plot(t,y1,'-r');subplot(1,2,2);plot(t,y2,'*b');
>> axis([0.5 1 -1 1]) # 设置x轴 -0.5~1 ,y轴 -1~1
>> clf # 清除画板上的内容
>> A=magic(5)
>> imagesc(A) # 图片形式显示矩阵
>> imagesc(A),colorbar,colormap gray; # 转成灰度显示
```
## 控制语句：for，while，if 语句

```python
>> v=zeros(10,1);
>> for i=1:10,
>     v(i)=i^2;
> end;

>> for i=1:10;v(i)=i^3;end;
>> for i=1:10
> v(i)=i^3;
> end;

>> indices=1:5
indices =

   1   2   3   4   5

>> for i=indices;disp(i);end;
 1
 2
 3
 4
 5

# --------------------------------

v =

      1
      8
     27
     64
    125
    216
    343
    512
    729
   1000

>> i=1;
>> while i<=5;v(i)=100;i=i+1;end;
>> v
v =

    100
    100
    100
    100
    100
    216
    343
    512
    729
   1000


>> i=1;
>> while true;
>   v(i)=999;
>   i=i+1;
>   if i==6;
>      break;
>   end;
> end;



>> i=1;
>> while true;
>   v(i)=999;
>   if i==6;
>      break;
>   end;
> end;

>> i=1;
>> while true;
>    if mod(i,2)==0; # mod求余数
>       continue;
>    end;
>    if i>length(v);
>       break;
>    end;
>    v(i)=10;
>    i=i+1;
> end;
# --------------------------

>> v=zeros(5,1);
>> v(2)=2;
>> if v(2)==2;
>    disp('the value is two');
>  elseif v(2)==1;
>    disp('the value is one');
>  else
>    disp('the value is other');
> end;
```
> exit 退出octave
> quit 退出octave

```python
>> function y=squareThisNumber(x);y=x.^2;end;
>> whos
>> squareThisNumber(5)
ans =  25
# --------或者-----------------
# 将 function y=squareThisNumber(x);y=x.^2;end; 写入一个名为squareThisNumber.m的文件中
# 切换到squareThisNumber.m所在目录下
# 直接运行
>> squareThisNumber(5)
ans =  25

# 或者添加squareThisNumber.m所在目录路径
>> addpath('C:\Users\Administrator')
# 直接运行
>> squareThisNumber(5)
ans =  25

#-----------------------------------

>> function [y1,y2]=squareAndCuberThisNumber(x);y1=x.^2;y2=x.^3;end;

>> x=[1 1;1 2;1 3]
x =

   1   1
   1   2
   1   3

>> y=[1;2;3]
y =

   1
   2
   3

>> theta=[0;1];
>> function J=costFunctionJ(X,y,theta);
>    m=size(X,1);
>    predictions=X*theta; % hypothesis
>    sqrErrors=(predictions-y).^2;  % squared errors
>    J=1/(2*m)*sum(sqrErrors);
>  end;
>> costFunctionJ(x,y,theta)
```

## 矢量
![这里写图片描述](http://img.blog.csdn.net/20180411112048392?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411112846686?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

----------

# 第7章 Logistic 回归
## 分类
![这里写图片描述](http://img.blog.csdn.net/20180411175641604?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411175648780?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411175656921?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 假设陈述
![这里写图片描述](http://img.blog.csdn.net/20180411183427270?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411183437604?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 决策界限
![这里写图片描述](http://img.blog.csdn.net/20180411200604418?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411200611468?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411200618417?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 代价函数
![这里写图片描述](http://img.blog.csdn.net/20180411201824181?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411201830720?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411201837916?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 简化代价函数与梯度下降

![这里写图片描述](http://img.blog.csdn.net/20180411205933056?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411205939813?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411205948093?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 高级优化
![这里写图片描述](http://img.blog.csdn.net/20180411215627645?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411215635246?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411215642863?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 多元分类：一对多
![这里写图片描述](http://img.blog.csdn.net/20180411220432796?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411220439788?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411220447120?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

----------


# 第8章 正则化
## 过拟合问题
![这里写图片描述](http://img.blog.csdn.net/20180408225508146?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408225516034?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408225523246?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

dropout --随机减少训练特征

## 代价函数
![这里写图片描述](http://img.blog.csdn.net/20180408230624666?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408230639242?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408230647861?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408230656398?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408230703687?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408230710961?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408230718641?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 线性回归的正则化
![这里写图片描述](http://img.blog.csdn.net/20180408231750015?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408231757771?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408231805496?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## Logistic 回归的正则化
![这里写图片描述](http://img.blog.csdn.net/20180408233552973?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408233601273?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180408233610050?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

# 第9章 神经网络学习
## 非线性假设

## 模型展示Ⅰ
![这里写图片描述](http://img.blog.csdn.net/20180409000640989?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180409000648213?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180409000655547?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 模型展示 II
![这里写图片描述](http://img.blog.csdn.net/20180411223236383?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411223244360?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411223250959?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 例子与直觉理解Ⅰ
![这里写图片描述](http://img.blog.csdn.net/20180411223930290?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411223938100?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411223945588?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411223952468?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 例子与直觉理解Ⅱ
![这里写图片描述](http://img.blog.csdn.net/20180411224607559?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411224613884?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 多元分类
![这里写图片描述](http://img.blog.csdn.net/20180411225052981?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180411225100702?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)


----------


# 第10章 神经网络参数的反向传播算法
## 代价函数
![这里写图片描述](http://img.blog.csdn.net/20180413232443591?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180413232451999?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 反向传播算法
![这里写图片描述](http://img.blog.csdn.net/20180413233901312?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180413233910254?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180413233919129?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)
## 理解反向传播
![这里写图片描述](http://img.blog.csdn.net/20180416001953754?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180416002002512?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180416002010668?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

## 使用注意：展开参数
![这里写图片描述](http://img.blog.csdn.net/20180417001323989?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180417001332570?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

![这里写图片描述](http://img.blog.csdn.net/20180417001341127?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2M3ODE3MDgyNDk=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

